# -*- coding: utf-8 -*-
"""mislnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DhKcK6vw2HxKSr-nfTsqp04LQpuUWRHD
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from torchvision import datasets, transforms

import matplotlib.pyplot as plt
device = torch.device("cuda:0" if (torch.cuda.is_available() ) else "cpu")
print("Using device: ", device)
# device="cpu"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Dresden\ Dataset

#pwd

class MislNetModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.ccnn_wts=nn.Parameter(torch.randn(size=[3,1,5,5]), requires_grad=True).to(device)
        self.conv2=nn.Conv2d(1,96,7, stride =2, padding=4)
        self.conv3=nn.Conv2d(96,64,5, stride=1, padding=2)
        self.conv4=nn.Conv2d(64,64,5, stride=1, padding=2)
        self.conv5=nn.Conv2d(64,128,1, stride =1)
        self.fc1=nn.Linear(128,200)
        self.fc2=nn.Linear(200,200)
        self.fc3=nn.Linear(200,27)  #6 is the number of out classes
        self.maxpool=nn.MaxPool2d(3,2)
        self.avgpool=nn.AvgPool2d(3,2)
    
    def remove_content(self):
        for i in range(3):
            self.ccnn_wts.data[i,0,2,2]=0
            self.ccnn_wts.data[i] /= torch.sum(self.ccnn_wts.data[i])
            self.ccnn_wts.data[i,0,2,2]=-1

    def forward(self, x):
        # x=x.to(device)
        self.remove_content()
        F.conv2d(x,self.ccnn_wts)
        x=self.conv2(x)
        x=self.maxpool(x)
        # x=nn.BatchNorm2d(96)(x)
        x=torch.tanh(x)

        x=self.conv3(x)
        x=self.maxpool(x)
        # x=nn.BatchNorm2d(64)(x)
        x=torch.tanh(x)

        x=self.conv4(x)
        x=self.maxpool(x)
        # x=nn.BatchNorm2d(64)(x)
        x=torch.tanh(x)

        x=self.conv5(x)
        x=self.avgpool(x)
        # x=nn.BatchNorm2d(128)(x)
        x=torch.tanh(x)

        x=torch.flatten(x,1)
        # print(x.shape)
        x=self.fc1(x)
        x=torch.tanh(x)
        x=self.fc2(x)
        x=torch.tanh(x)
        x=self.fc3(x)
        x=F.softmax(x,1)
        return x

model=MislNetModel().to(device)
print(model)


transform=transforms.Compose([
                              transforms.Resize((64,64)),
                              transforms.Grayscale(),
                              transforms.ToTensor(),
                              transforms.Normalize((0.5), (0.5))
])
dataset=datasets.ImageFolder('./Dresden Dataset/',transform=transform)
dataloader=torch.utils.data.DataLoader(dataset, batch_size=32,
                                         shuffle=True)
num_train=len(dataset)*0.8
num_train=int(num_train)
train_dataset, test_dataset=torch.utils.data.random_split(dataset, [num_train, len(dataset)-num_train])
train_dataloader=torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataloader=torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)

images,label=next(iter(train_dataloader))

print(model(images).shape)

import torch.optim as optim
criterion=nn.CrossEntropyLoss()
optimizer=optim.SGD(model.parameters(), momentum=0.95, weight_decay=0.0005, lr=1e-3)

for epoch in range(1):
    running_loss=0
    for i,data in enumerate(train_dataloader,0):
        inputs,labels=data
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs=model(inputs)
        print(outputs.shape, labels.shape, min(labels), max(labels))
        loss=criterion(outputs,labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 30 == 29:    # print every 30 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

correct = 0
total = 0
# since we're not training, we don't need to calculate the gradients for our outputs
with torch.no_grad():
    for data in test_dataloader:
        images, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        # calculate outputs by running images through the network
        outputs = model(images)
        # the class with the highest energy is what we choose as prediction
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
torch.save(model.state_dict(), './checkpoints/checkpoint.pt' )
